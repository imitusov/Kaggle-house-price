{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import altair as alt\n",
    "from altair.expr import datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'D:\\HPDemo\\Projects\\Kaggle_house_price\\train.csv')\n",
    "test = pd.read_csv(r'D:\\HPDemo\\Projects\\Kaggle_house_price\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data size before dropping Id feature is : (1460, 81) \n",
      "The test data size before dropping Id feature is : (1459, 80) \n",
      "\n",
      "The train data size after dropping Id feature is : (1460, 80) \n",
      "The test data size after dropping Id feature is : (1459, 79) \n"
     ]
    }
   ],
   "source": [
    "print(\"The train data size before dropping Id feature is : {} \".format(train.shape))\n",
    "print(\"The test data size before dropping Id feature is : {} \".format(test.shape))\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "train.drop(\"Id\", axis = 1, inplace = True)\n",
    "test.drop(\"Id\", axis = 1, inplace = True)\n",
    "\n",
    "#check again the data size after dropping the 'Id' variable\n",
    "print(\"\\nThe train data size after dropping Id feature is : {} \".format(train.shape)) \n",
    "print(\"The test data size after dropping Id feature is : {} \".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data size is : (2917, 79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\classic_jl_lgbm\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "y_train = train.SalePrice.values\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>99.691464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>96.400411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>93.212204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>80.425094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>48.680151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>16.660953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>5.450806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>5.450806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>5.450806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>5.450806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>5.382242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>2.811107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>2.811107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>2.776826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>2.742544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>2.708262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>0.822763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>0.788481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSZoning</th>\n",
       "      <td>0.137127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>0.068564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing Ratio\n",
       "PoolQC            99.691464\n",
       "MiscFeature       96.400411\n",
       "Alley             93.212204\n",
       "Fence             80.425094\n",
       "FireplaceQu       48.680151\n",
       "LotFrontage       16.660953\n",
       "GarageQual         5.450806\n",
       "GarageCond         5.450806\n",
       "GarageFinish       5.450806\n",
       "GarageYrBlt        5.450806\n",
       "GarageType         5.382242\n",
       "BsmtExposure       2.811107\n",
       "BsmtCond           2.811107\n",
       "BsmtQual           2.776826\n",
       "BsmtFinType2       2.742544\n",
       "BsmtFinType1       2.708262\n",
       "MasVnrType         0.822763\n",
       "MasVnrArea         0.788481\n",
       "MSZoning           0.137127\n",
       "BsmtFullBath       0.068564"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\n",
    "all_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\n",
    "all_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\n",
    "all_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\n",
    "all_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\n",
    "all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "all_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\n",
    "all_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\n",
    "all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "all_data = all_data.drop(['Utilities'], axis=1)\n",
    "all_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\n",
    "all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
    "all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")\n",
    "\n",
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all_data: (2917, 78)\n",
      "\n",
      "Skew in numerical features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>21.950962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>17.697766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>13.116240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>12.090757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>11.377932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandSlope</th>\n",
       "      <td>4.975813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>4.302763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>4.146636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>4.004404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>3.947131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Skew\n",
       "MiscVal        21.950962\n",
       "PoolArea       17.697766\n",
       "LotArea        13.116240\n",
       "LowQualFinSF   12.090757\n",
       "3SsnPorch      11.377932\n",
       "LandSlope       4.975813\n",
       "KitchenAbvGr    4.302763\n",
       "BsmtFinSF2      4.146636\n",
       "EnclosedPorch   4.004404\n",
       "ScreenPorch     3.947131"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n",
    "\n",
    "\n",
    "#Changing OverallCond into a categorical variable\n",
    "all_data['OverallCond'] = all_data['OverallCond'].astype(str)\n",
    "\n",
    "\n",
    "#Year and month sold are transformed into categorical features.\n",
    "all_data['YrSold'] = all_data['YrSold'].astype(str)\n",
    "all_data['MoSold'] = all_data['MoSold'].astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(all_data[c].values)) \n",
    "    all_data[c] = lbl.transform(list(all_data[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape all_data: {}'.format(all_data.shape))\n",
    "\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: x.dropna().skew()).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 36 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness.Skew) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 220)\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.get_dummies(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\classic_jl_lgbm\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.005, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_1 = rmsle_cv(lasso)\n",
    "score_2 = rmsle_cv(ENet)\n",
    "score_3 = rmsle_cv(KRR)\n",
    "#score_4 = rmsle_cv(GBoost)\n",
    "score_5 = rmsle_cv(model_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11027227044577288 0.11024647070496787 0.17803703736736706 0.14265822667278366\n"
     ]
    }
   ],
   "source": [
    "print(score_1.mean(), score_2.mean(), score_3.mean(), score_5.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, bagging_seed=9,\n",
       "       boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       feature_fraction=0.2319, feature_fraction_seed=9,\n",
       "       learning_rate=0.005, max_bin=55, max_depth=-1, min_child_samples=20,\n",
       "       min_child_weight=0.001, min_data_in_leaf=6, min_split_gain=0.0,\n",
       "       min_sum_hessian_in_leaf=11, n_estimators=720, n_jobs=-1,\n",
       "       num_leaves=5, objective='regression', random_state=None,\n",
       "       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_lgb.predict(test)\n",
    "pred = np.exp(pred)\n",
    "solution = pd.DataFrame(pred, index=test_ID, columns=['SalePrice'])\n",
    "solution.to_csv('submission_one.csv', index_label='Id', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [x for x in models]\n",
    "        \n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        prediction = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        \n",
    "        return np.mean(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 0.1185 (0.0075)\n",
      "\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = (ENet, KRR, lasso)\n",
    "averaged_models = AveragingModels(models=models)\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n",
    "        oof = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                oof[holdout_index, i] = y_pred\n",
    "            \n",
    "        self.meta_model_.fit(oof, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([\n",
    "                model.predict(X) for model in base_models]).mean(axis=1)\n",
    "                for base_models in self.base_models_\n",
    "        ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Averaged models score: 0.1101 (0.0078)\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_averaged_models = StackingAveragedModels(base_models=(ENet, KRR), meta_model=lasso)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, MultiTaskLasso, ElasticNet, BayesianRidge, LassoLars, SGDRegressor, HuberRegressor\n",
    "from sklearn.svm import SVR, NuSVR, LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ridge = Ridge(random_state=42)\n",
    "clf_lasso = Lasso(random_state=42)\n",
    "clf_Enet = ElasticNet(random_state=42)\n",
    "clf_Bayes = BayesianRidge()\n",
    "clf_lassolars = LassoLars()\n",
    "clf_sgd = SGDRegressor()\n",
    "clf_huber = HuberRegressor()\n",
    "clf_SVR = SVR()\n",
    "clf_nuSVR = NuSVR()\n",
    "clf_knnr = KNeighborsRegressor()\n",
    "clf_tree = DecisionTreeRegressor()\n",
    "\n",
    "classifiers = [clf_ridge, clf_lasso, clf_Enet, clf_Bayes, clf_lassolars, clf_sgd, clf_huber, clf_SVR, clf_nuSVR, clf_knnr, clf_tree]\n",
    "\n",
    "params = {\n",
    "    0: {'clf__alpha': np.linspace(0.01, 1, 10)},\n",
    "    1: {'clf__alpha': np.linspace(0.01, 1, 100)},\n",
    "    2: {'clf__alpha': np.linspace(0.01, 1, 10), 'clf__l1_ratio': np.linspace(0.01, 1, 10)},\n",
    "    3: {'clf__alpha_1': [1e-8, 1e-7, 1e-6, 1e-5, 1e-4], 'clf__alpha_2': [1e-8, 1e-7, 1e-6, 1e-5, 1e-4]},\n",
    "    4: {'clf__alpha': np.linspace(0.01, 1, 100)},\n",
    "    5: {'clf__alpha': np.linspace(0.01, 1, 50), 'clf__l1_ratio': np.linspace(0.01, 1, 50)},\n",
    "    6: {'clf__alpha': np.linspace(0.01, 1, 50), 'clf__epsilon': np.linspace(1, 2, 10)},\n",
    "    7: {'clf__kernel' : ['rbf', 'linear', 'poly', 'sigmoid',], 'clf__C': np.linspace(0.1, 1, 6), 'clf__epsilon': np.linspace(0.1, 1, 6)},\n",
    "    8: {'clf__kernel' : ['rbf', 'linear', 'poly', 'sigmoid'], 'clf__nu': np.linspace(0.1, 1, 6)},\n",
    "    9: {'clf__n_neighbors': [9], 'clf__weights': ['distance']},\n",
    "    10: {'clf__max_depth': [5, 6, 8, 10, 12, 20], 'clf__min_samples_split': [2, 3, 5, 10, 20, 30], 'clf__min_samples_leaf': [2, 3, 5, 10, 20, 30]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 19)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.9999)\n",
    "pca.fit(train)\n",
    "pca_train = pca.transform(train)\n",
    "pca_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2500 candidates, totalling 7500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2215 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 5715 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 7500 out of 7500 | elapsed:   33.1s finished\n",
      "D:\\Anaconda\\envs\\classic_jl_lgbm\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 963 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:   23.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 432 out of 432 | elapsed:   12.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   18.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed:    3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed:    7.3s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_params = {}\n",
    "\n",
    "for ix, clf in enumerate(classifiers):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "    \n",
    "    CV = GridSearchCV(pipeline, param_grid=params[ix], scoring='neg_mean_squared_error', verbose=True, n_jobs=-1)\n",
    "    CV.fit(pca_train, y_train)\n",
    "    best_params[classifiers[ix]] = CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.01}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params[classifiers[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ridge = Ridge(random_state=42, alpha=1.0)\n",
    "clf_lasso = Lasso(random_state=42, alpha=0.01)\n",
    "clf_Enet = ElasticNet(random_state=42, alpha=0.01, l1_ratio=0.23)\n",
    "clf_Bayes = BayesianRidge(alpha_1=1e-08, alpha_2=0.0001)\n",
    "clf_lassolars = LassoLars(alpha=0.01)\n",
    "clf_sgd = SGDRegressor(alpha=0.09081632653061224, l1_ratio=0.5151020408163265)\n",
    "clf_huber = HuberRegressor(alpha=0.0001, epsilon=4.2)\n",
    "clf_SVR = SVR(kernel='linear', C=0.82, epsilon=0.1)\n",
    "clf_nuSVR = NuSVR(kernel='linear', nu=0.45999999999999996)\n",
    "clf_knnr = KNeighborsRegressor(n_neighbors=9, weights='distance')\n",
    "clf_tree = DecisionTreeRegressor(max_depth=12, min_samples_leaf=20, min_samples_split=10)\n",
    "clf_gb = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf, verbose=True, n_jobs=-1))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.6s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_1 = rmsle_cv(clf_ridge)\n",
    "score_2 = rmsle_cv(clf_lasso)\n",
    "score_3 = rmsle_cv(clf_Enet)\n",
    "score_4 = rmsle_cv(clf_Bayes)\n",
    "score_5 = rmsle_cv(clf_lassolars)\n",
    "#score_6 = rmsle_cv(clf_sgd)\n",
    "score_7 = rmsle_cv(clf_huber)\n",
    "score_8 = rmsle_cv(clf_SVR)\n",
    "score_9 = rmsle_cv(clf_nuSVR)\n",
    "score_10 = rmsle_cv(clf_knnr)\n",
    "score_11 = rmsle_cv(clf_tree)\n",
    "score_12 = rmsle_cv(clf_gb)\n",
    "\n",
    "scores = ['scores_' + x for x in range(13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16080112411425276 0.16071743192601817 0.1606740956646162 0.16078689302204777 0.3994682097577765 0.2318819952205305 0.23488593566299315 0.16913801653625954\n"
     ]
    }
   ],
   "source": [
    "print(score_1.mean(), score_2.mean(), score_3.mean(), score_4.mean(), score_5.mean(), score_10.mean(), score_11.mean(), score_12.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
