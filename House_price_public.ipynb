{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import altair as alt\n",
    "from altair.expr import datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'D:\\HPDemo\\Projects\\Kaggle_house_price\\train.csv')\n",
    "test = pd.read_csv(r'D:\\HPDemo\\Projects\\Kaggle_house_price\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data size before dropping Id feature is : (1460, 81) \n",
      "The test data size before dropping Id feature is : (1459, 80) \n",
      "\n",
      "The train data size after dropping Id feature is : (1460, 80) \n",
      "The test data size after dropping Id feature is : (1459, 79) \n"
     ]
    }
   ],
   "source": [
    "print(\"The train data size before dropping Id feature is : {} \".format(train.shape))\n",
    "print(\"The test data size before dropping Id feature is : {} \".format(test.shape))\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "train.drop(\"Id\", axis = 1, inplace = True)\n",
    "test.drop(\"Id\", axis = 1, inplace = True)\n",
    "\n",
    "#check again the data size after dropping the 'Id' variable\n",
    "print(\"\\nThe train data size after dropping Id feature is : {} \".format(train.shape)) \n",
    "print(\"The test data size after dropping Id feature is : {} \".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data size is : (2917, 79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\classic_jl_lgbm\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "y_train = train.SalePrice.values\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>99.691464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>96.400411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>93.212204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>80.425094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>48.680151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>16.660953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>5.450806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>5.450806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>5.450806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>5.450806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>5.382242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>2.811107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>2.811107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>2.776826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>2.742544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>2.708262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>0.822763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>0.788481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSZoning</th>\n",
       "      <td>0.137127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>0.068564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing Ratio\n",
       "PoolQC            99.691464\n",
       "MiscFeature       96.400411\n",
       "Alley             93.212204\n",
       "Fence             80.425094\n",
       "FireplaceQu       48.680151\n",
       "LotFrontage       16.660953\n",
       "GarageQual         5.450806\n",
       "GarageCond         5.450806\n",
       "GarageFinish       5.450806\n",
       "GarageYrBlt        5.450806\n",
       "GarageType         5.382242\n",
       "BsmtExposure       2.811107\n",
       "BsmtCond           2.811107\n",
       "BsmtQual           2.776826\n",
       "BsmtFinType2       2.742544\n",
       "BsmtFinType1       2.708262\n",
       "MasVnrType         0.822763\n",
       "MasVnrArea         0.788481\n",
       "MSZoning           0.137127\n",
       "BsmtFullBath       0.068564"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\n",
    "all_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\n",
    "all_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\n",
    "all_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\n",
    "all_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\n",
    "all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "all_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\n",
    "all_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\n",
    "all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "all_data = all_data.drop(['Utilities'], axis=1)\n",
    "all_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\n",
    "all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
    "all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")\n",
    "\n",
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all_data: (2917, 78)\n",
      "\n",
      "Skew in numerical features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>21.950962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>17.697766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>13.116240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>12.090757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>11.377932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandSlope</th>\n",
       "      <td>4.975813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>4.302763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>4.146636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>4.004404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>3.947131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Skew\n",
       "MiscVal        21.950962\n",
       "PoolArea       17.697766\n",
       "LotArea        13.116240\n",
       "LowQualFinSF   12.090757\n",
       "3SsnPorch      11.377932\n",
       "LandSlope       4.975813\n",
       "KitchenAbvGr    4.302763\n",
       "BsmtFinSF2      4.146636\n",
       "EnclosedPorch   4.004404\n",
       "ScreenPorch     3.947131"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n",
    "\n",
    "\n",
    "#Changing OverallCond into a categorical variable\n",
    "all_data['OverallCond'] = all_data['OverallCond'].astype(str)\n",
    "\n",
    "\n",
    "#Year and month sold are transformed into categorical features.\n",
    "all_data['YrSold'] = all_data['YrSold'].astype(str)\n",
    "all_data['MoSold'] = all_data['MoSold'].astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(all_data[c].values)) \n",
    "    all_data[c] = lbl.transform(list(all_data[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape all_data: {}'.format(all_data.shape))\n",
    "\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: x.dropna().skew()).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 36 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness.Skew) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 220)\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.get_dummies(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\classic_jl_lgbm\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [x for x in self.models]\n",
    "        \n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        prediction = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        \n",
    "        return np.mean(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n",
    "        oof = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                oof[holdout_index, i] = y_pred\n",
    "            \n",
    "        self.meta_model_.fit(oof, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([\n",
    "                model.predict(X) for model in base_models]).mean(axis=1)\n",
    "                for base_models in self.base_models_\n",
    "        ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, MultiTaskLasso, ElasticNet, BayesianRidge, LassoLars, SGDRegressor, HuberRegressor\n",
    "from sklearn.svm import SVR, NuSVR, LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ridge = Ridge(random_state=42)\n",
    "clf_lasso = Lasso(random_state=42)\n",
    "clf_Enet = ElasticNet(random_state=42)\n",
    "clf_Bayes = BayesianRidge()\n",
    "clf_lassolars = LassoLars()\n",
    "\n",
    "classifiers_one_names = ['Ridge', 'Lasso', 'ElasticNet', 'BayesianRidge', 'LassoLars']\n",
    "\n",
    "classifiers_one = [clf_ridge, clf_lasso, clf_Enet, clf_Bayes, clf_lassolars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download presaved models\n",
    "\n",
    "for ix, clf in enumerate(classifiers_one):\n",
    "    classifiers_one[ix] = joblib.load(str(classifiers_one_names[ix]) + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_one = {\n",
    "    0: {'clf__alpha': np.linspace(0.9, 1, 101)},\n",
    "    1: {'clf__alpha': np.linspace(0.0001, 0.002, 101)},\n",
    "    2: {'clf__alpha': np.linspace(0.0001, 0.004, 101), 'clf__l1_ratio': np.linspace(0.7, 0.8, 21)},\n",
    "    3: {'clf__alpha_1': np.linspace(1e-9, 1e-7, 20), 'clf__alpha_2': np.linspace(0.0001, 0.1, 21)},\n",
    "    4: {'clf__alpha': np.linspace(0.00001, 0.001, 101)}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 101 candidates, totalling 505 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 505 out of 505 | elapsed:   18.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 101 candidates, totalling 505 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done 505 out of 505 | elapsed:   36.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2121 candidates, totalling 10605 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 9792 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 10605 out of 10605 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 420 candidates, totalling 2100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2100 out of 2100 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 101 candidates, totalling 505 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   17.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 505 out of 505 | elapsed:   18.9s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_params_one = {}\n",
    "\n",
    "for ix, model in enumerate(classifiers_one):\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('robust', RobustScaler()),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    CV = GridSearchCV(pipeline, param_grid=params_one[ix], cv=kf, verbose=True, n_jobs=-1)\n",
    "    CV.fit(train.values, y_train)\n",
    "    classifiers_one[ix] = CV.best_estimator_.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models if necessary\n",
    "\n",
    "for i in classifiers_one:\n",
    "    joblib.dump(i, (str(i).split('(')[0] + '.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_one =[]\n",
    "for i in classifiers_one:\n",
    "    score_one.append(rmsle_cv(i).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AveragingModels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-391f3f30230c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAveragingModels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifiers_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmsle_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AveragingModels' is not defined"
     ]
    }
   ],
   "source": [
    "average = AveragingModels(models=classifiers_one)\n",
    "print(rmsle_cv(average).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_huber = HuberRegressor()\n",
    "clf_SVR = SVR()\n",
    "clf_tree = RandomForestRegressor(random_state=42)\n",
    "\n",
    "classifiers_two_names = ['HuberRegressor', 'SVR', 'RandomForestRegressor']\n",
    "\n",
    "classifiers_two = [clf_huber, clf_SVR, clf_tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download presaved models if necessary\n",
    "\n",
    "for ix, clf in enumerate(classifiers_two):\n",
    "    classifiers_two[ix] = joblib.load(str(classifiers_two_names[ix]) + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 110 candidates, totalling 550 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   54.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 550 out of 550 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 121 candidates, totalling 605 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=-1)]: Done 568 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 605 out of 605 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "params_two = {\n",
    "    0: {'clf__alpha': np.linspace(0.0001, 1, 11), 'clf__epsilon': [x for x in range(1, 11)]},\n",
    "    1: {'clf__kernel': ['linear'], 'clf__C': np.linspace(0.01, 1, 11), 'clf__epsilon': [x for x in range(11)]},\n",
    "    2: {'clf__max_depth': [5, 6, 8, 10, 12, 20], 'clf__min_samples_split': [2, 3, 5, 10, 20, 30], 'clf__min_samples_leaf': [2, 3, 5, 10, 20, 30],\n",
    "        'clf__n_estimators': [20]}\n",
    "}\n",
    "\n",
    "best_params_two = {}\n",
    "\n",
    "\n",
    "for ix, model in enumerate(classifiers_two):\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('robust', RobustScaler()),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    CV = GridSearchCV(pipeline, param_grid=params_two[ix], cv=kf, verbose=True, n_jobs=-1)\n",
    "    CV.fit(train.values, y_train)\n",
    "    classifiers_two[ix] = CV.best_estimator_.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models if necessary\n",
    "\n",
    "for i in classifiers_two:\n",
    "    joblib.dump(i, (str(i).split('(')[0] + '.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "score_two =[]\n",
    "for i in classifiers_two:\n",
    "    score_two.append(rmsle_cv(i).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = AveragingModels(models=classifiers_two)\n",
    "print(rmsle_cv(average).mean(), score_two)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
