{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import altair as alt\n",
    "from altair.expr import datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'D:\\HPDemo\\Projects\\Kaggle_house_price\\train.csv')\n",
    "test = pd.read_csv(r'D:\\HPDemo\\Projects\\Kaggle_house_price\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data size before dropping Id feature is : (1460, 81) \n",
      "The test data size before dropping Id feature is : (1459, 80) \n",
      "\n",
      "The train data size after dropping Id feature is : (1460, 80) \n",
      "The test data size after dropping Id feature is : (1459, 79) \n"
     ]
    }
   ],
   "source": [
    "print(\"The train data size before dropping Id feature is : {} \".format(train.shape))\n",
    "print(\"The test data size before dropping Id feature is : {} \".format(test.shape))\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "train.drop(\"Id\", axis = 1, inplace = True)\n",
    "test.drop(\"Id\", axis = 1, inplace = True)\n",
    "\n",
    "#check again the data size after dropping the 'Id' variable\n",
    "print(\"\\nThe train data size after dropping Id feature is : {} \".format(train.shape)) \n",
    "print(\"The test data size after dropping Id feature is : {} \".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data size is : (2917, 79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\classic_jl_lgbm\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "y_train = train.SalePrice.values\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>99.691464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>96.400411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>93.212204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>80.425094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>48.680151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>16.660953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>5.450806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>5.450806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>5.450806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>5.450806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>5.382242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>2.811107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>2.811107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>2.776826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>2.742544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>2.708262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>0.822763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>0.788481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSZoning</th>\n",
       "      <td>0.137127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>0.068564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing Ratio\n",
       "PoolQC            99.691464\n",
       "MiscFeature       96.400411\n",
       "Alley             93.212204\n",
       "Fence             80.425094\n",
       "FireplaceQu       48.680151\n",
       "LotFrontage       16.660953\n",
       "GarageQual         5.450806\n",
       "GarageCond         5.450806\n",
       "GarageFinish       5.450806\n",
       "GarageYrBlt        5.450806\n",
       "GarageType         5.382242\n",
       "BsmtExposure       2.811107\n",
       "BsmtCond           2.811107\n",
       "BsmtQual           2.776826\n",
       "BsmtFinType2       2.742544\n",
       "BsmtFinType1       2.708262\n",
       "MasVnrType         0.822763\n",
       "MasVnrArea         0.788481\n",
       "MSZoning           0.137127\n",
       "BsmtFullBath       0.068564"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\n",
    "all_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\n",
    "all_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\n",
    "all_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\n",
    "all_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\n",
    "all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "all_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\n",
    "all_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\n",
    "all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "all_data = all_data.drop(['Utilities'], axis=1)\n",
    "all_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\n",
    "all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
    "all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")\n",
    "\n",
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all_data: (2917, 78)\n",
      "\n",
      "Skew in numerical features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>21.950962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>17.697766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>13.116240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>12.090757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>11.377932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandSlope</th>\n",
       "      <td>4.975813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>4.302763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>4.146636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>4.004404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>3.947131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Skew\n",
       "MiscVal        21.950962\n",
       "PoolArea       17.697766\n",
       "LotArea        13.116240\n",
       "LowQualFinSF   12.090757\n",
       "3SsnPorch      11.377932\n",
       "LandSlope       4.975813\n",
       "KitchenAbvGr    4.302763\n",
       "BsmtFinSF2      4.146636\n",
       "EnclosedPorch   4.004404\n",
       "ScreenPorch     3.947131"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n",
    "\n",
    "\n",
    "#Changing OverallCond into a categorical variable\n",
    "all_data['OverallCond'] = all_data['OverallCond'].astype(str)\n",
    "\n",
    "\n",
    "#Year and month sold are transformed into categorical features.\n",
    "all_data['YrSold'] = all_data['YrSold'].astype(str)\n",
    "all_data['MoSold'] = all_data['MoSold'].astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(all_data[c].values)) \n",
    "    all_data[c] = lbl.transform(list(all_data[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape all_data: {}'.format(all_data.shape))\n",
    "\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: x.dropna().skew()).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 36 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness.Skew) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 220)\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.get_dummies(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\classic_jl_lgbm\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [x for x in self.models]\n",
    "        \n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        prediction = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        \n",
    "        return np.mean(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n",
    "        oof = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                oof[holdout_index, i] = y_pred\n",
    "            \n",
    "        self.meta_model_.fit(oof, y)\n",
    "        return self, oof\n",
    "    \n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([\n",
    "                model.predict(X) for model in base_models]).mean(axis=1)\n",
    "                for base_models in self.base_models_\n",
    "        ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, MultiTaskLasso, ElasticNet, BayesianRidge, LassoLars, SGDRegressor, HuberRegressor\n",
    "from sklearn.svm import SVR, NuSVR, LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ridge = Ridge(random_state=42)\n",
    "clf_lasso = Lasso(random_state=42)\n",
    "clf_Enet = ElasticNet(random_state=42)\n",
    "clf_Bayes = BayesianRidge()\n",
    "clf_lassolars = LassoLars()\n",
    "\n",
    "classifiers_one_names = ['Ridge', 'Lasso', 'ElasticNet', 'BayesianRidge', 'LassoLars']\n",
    "\n",
    "classifiers_one = [clf_ridge, clf_lasso, clf_Enet, clf_Bayes, clf_lassolars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download presaved models\n",
    "\n",
    "for ix, clf in enumerate(classifiers_one):\n",
    "    classifiers_one[ix] = joblib.load(str(classifiers_one_names[ix]) + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_one = {\n",
    "    0: {'clf__alpha': np.linspace(0.9, 1, 101)},\n",
    "    1: {'clf__alpha': np.linspace(0.0001, 0.002, 101)},\n",
    "    2: {'clf__alpha': np.linspace(0.0001, 0.004, 101), 'clf__l1_ratio': np.linspace(0.7, 0.8, 21)},\n",
    "    3: {'clf__alpha_1': np.linspace(1e-9, 1e-7, 20), 'clf__alpha_2': np.linspace(0.0001, 0.1, 21)},\n",
    "    4: {'clf__alpha': np.linspace(0.00001, 0.001, 101)}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 101 candidates, totalling 505 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 505 out of 505 | elapsed:   18.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 101 candidates, totalling 505 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done 505 out of 505 | elapsed:   36.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2121 candidates, totalling 10605 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 9792 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 10605 out of 10605 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 420 candidates, totalling 2100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2100 out of 2100 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 101 candidates, totalling 505 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   17.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 505 out of 505 | elapsed:   18.9s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_params_one = {}\n",
    "\n",
    "for ix, model in enumerate(classifiers_one):\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('robust', RobustScaler()),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    CV = GridSearchCV(pipeline, param_grid=params_one[ix], cv=kf, verbose=True, n_jobs=-1, error_score=)\n",
    "    CV.fit(train.values, y_train)\n",
    "    classifiers_one[ix] = CV.best_estimator_.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models if necessary\n",
    "\n",
    "for i in classifiers_one:\n",
    "    joblib.dump(i, (str(i).split('(')[0] + '.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_one =[]\n",
    "for i in classifiers_one:\n",
    "    score_one.append(rmsle_cv(i).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11068969465539655 [0.11610829251063215, 0.11051513762399483, 0.11056214589165221, 0.11259532646798587, 0.11132288080533648]\n"
     ]
    }
   ],
   "source": [
    "average = AveragingModels(models=classifiers_one)\n",
    "print(rmsle_cv(average).mean(), score_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lgb = lgb.LGBMRegressor()\n",
    "\n",
    "stacked = StackingAveragedModels(classifiers_one, clf_lgb)\n",
    "\n",
    "_, off = stacked.fit(train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[0.12059857 0.12876104 0.12977559 0.11902479 0.10977003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "clf_tree_d = DecisionTreeRegressor(random_state=42)\n",
    "params_tree = {\n",
    "    'max_depth': [3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "\n",
    "CV_tree = GridSearchCV(clf_tree_d, params_tree, cv=kf, verbose=True, n_jobs=-1)\n",
    "CV_tree.fit(off, y_train)\n",
    "print(rmsle_cv(CV_tree.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   18.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   30.5s finished\n"
     ]
    }
   ],
   "source": [
    "clf_ada = AdaBoostRegressor()\n",
    "clf_kkr = KernelRidge()\n",
    "\n",
    "classifiers_three = [clf_ada, clf_kkr]\n",
    "\n",
    "classifiers_three_names = ['AdaBoostRegressor', 'KernelRidge']\n",
    "\n",
    "params_three ={\n",
    "    0: {'clf__learning_rate': np.linspace(0.042, 0.043, 10), 'clf__loss': ['exponential'], 'clf__base_estimator': [CV_tree.best_estimator_, None]}, \n",
    "    1: {'clf__alpha': np.linspace(0.097, 0.1, 50), 'clf__kernel': ['polynomial'], 'clf__degree': [4]}\n",
    "}\n",
    "\n",
    "for ix, model in enumerate(classifiers_three):\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42).get_n_splits()\n",
    "    CV = GridSearchCV(pipeline, params_three[ix], cv=kf, verbose=True, n_jobs=-1)\n",
    "    CV.fit(off, y_train)\n",
    "    classifiers_three[ix] = CV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models if necessary\n",
    "\n",
    "for i in classifiers_three:\n",
    "    joblib.dump(i, (str(i).split('(')[0] + '.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgbm = {\n",
    "    'max_depth': [5],\n",
    "    'learning_rate': np.linspace(0.003, 0.003, 1),\n",
    "    'n_estimators': [3000],\n",
    "    'num_leaves': [30],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['regression_l1'],\n",
    "    'random_state' : [501], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.0001],\n",
    "    'subsample' : [1],\n",
    "    'subsample_for_bin': [300],\n",
    "    'reg_alpha' : np.linspace(0.0001, 0.0001, 1),\n",
    "    'reg_lambda' : np.linspace(0.0001, 0.0001, 1),\n",
    "    'subsample' : [1],\n",
    "    'subsample_freq': [1],\n",
    "    'min_split_gain': [0.5],\n",
    "    'min_child_weight': [1],\n",
    "    'min_child_samples': [5],\n",
    "    'scale_pos_weight': [1],\n",
    "    'max_bin': [100],\n",
    "    'bagging_fraction': [1],\n",
    "    'bagging_freq': [5],\n",
    "    'feature_fraction': [1],\n",
    "    'feature_fraction_seed': [9],\n",
    "    'bagging_seed': [9],\n",
    "    'mid_data_in_leaf': [2],\n",
    "    'min_sum_hessian_in_leaf': [11]\n",
    "    \n",
    "}\n",
    "\n",
    "clf_lgb = lgb.LGBMRegressor(boosting_type= 'gbdt',\n",
    "          objective = 'binary',\n",
    "          n_jobs = 3, # Updated from 'nthread'\n",
    "          silent = True,\n",
    "          max_depth = params_lgbm['max_depth'],\n",
    "          num_leaves = params_lgbm['num_leaves'],\n",
    "          subsample_for_bin = params_lgbm['subsample_for_bin'],\n",
    "          subsample = params_lgbm['subsample'],\n",
    "          subsample_freq = params_lgbm['subsample_freq'],\n",
    "          min_split_gain = params_lgbm['min_split_gain'],\n",
    "          min_child_weight = params_lgbm['min_child_weight'],\n",
    "          min_child_samples = params_lgbm['min_child_samples'],\n",
    "          scale_pos_weight = params_lgbm['scale_pos_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       learning_rate=0.1, max_depth=[5], min_child_samples=[5],\n",
       "       min_child_weight=[1], min_split_gain=[0.5], n_estimators=100,\n",
       "       n_jobs=3, num_leaves=[30], objective='binary', random_state=None,\n",
       "       reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=[1], silent=True,\n",
       "       subsample=[1], subsample_for_bin=[300], subsample_freq=[1]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [5], 'learning_rate': array([0.003]), 'n_estimators': [3000], 'num_leaves': [30], 'boosting_type': ['gbdt'], 'objective': ['regression_l1'], 'random_state': [501], 'colsample_bytree': [0.0001], 'subsample': [1], 'subsample_for_bin': [300], 'reg_alpha': array([0.0001]), 'reg_..._fraction_seed': [9], 'bagging_seed': [9], 'mid_data_in_leaf': [2], 'min_sum_hessian_in_leaf': [11]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV = GridSearchCV(clf_lgb, params_lgbm, cv=kf, verbose=True, n_jobs=-1)\n",
    "CV.fit(off, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=41)\n",
    "    rmse= np.sqrt(-cross_val_score(model, off, y_train, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "scaler.fit(train.values)\n",
    "\n",
    "prediction = np.column_stack([\n",
    "    i.predict(scaler.transform(test.values)) for i in classifiers_one\n",
    "])\n",
    "\n",
    "prediction_two = np.column_stack([\n",
    "    i.predict(prediction) for i in classifiers_three\n",
    "])\n",
    "\n",
    "prediction_three = CV.best_estimator_.predict(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_final = np.column_stack([np.expm1(prediction_two), np.expm1(prediction_three)]).mean(axis=1)\n",
    "prediction_final\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test_ID\n",
    "submission['SalePrice'] = prediction_final\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
